{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>The Shining, you know what's weird about this ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Rented the video for a slow Saturday night. Fi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Two Hands is a highly enjoyable Aussie crime c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>It is easy for a movie that tries to be suspen...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>A gritty presentation of the decay of family v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "814  The Shining, you know what's weird about this ...  positive\n",
       "525  Rented the video for a slow Saturday night. Fi...  positive\n",
       "694  Two Hands is a highly enjoyable Aussie crime c...  positive\n",
       "547  It is easy for a movie that tries to be suspen...  negative\n",
       "88   A gritty presentation of the decay of family v...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB.csv')\n",
    "df = df.sample(500)\n",
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('ÿõ', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['review'] = df['review'].apply(lower_case)\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\n",
    "        df['review'] = df['review'].apply(removing_numbers)\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\n",
    "        df['review'] = df['review'].apply(removing_urls)\n",
    "        df['review'] = df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>shining know what s weird movie movie everyone...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>rented video slow saturday night first viewing...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>two hand highly enjoyable aussie crime caper u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>easy movie try suspenseful wind merely uninter...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>gritty presentation decay family value human d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "814  shining know what s weird movie movie everyone...  positive\n",
       "525  rented video slow saturday night first viewing...  positive\n",
       "694  two hand highly enjoyable aussie crime caper u...  positive\n",
       "547  easy movie try suspenseful wind merely uninter...  negative\n",
       "88   gritty presentation decay family value human d...  positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    254\n",
       "positive    246\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\n",
    "df = df[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>shining know what s weird movie movie everyone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>rented video slow saturday night first viewing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>two hand highly enjoyable aussie crime caper u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>easy movie try suspenseful wind merely uninter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>gritty presentation decay family value human d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "814  shining know what s weird movie movie everyone...          1\n",
       "525  rented video slow saturday night first viewing...          1\n",
       "694  two hand highly enjoyable aussie crime caper u...          1\n",
       "547  easy movie try suspenseful wind merely uninter...          0\n",
       "88   gritty presentation decay family value human d...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 14:53:45 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1e3a5b8fa7f540568a6ca86584c216b8', creation_time=1758878627627, experiment_id='0', last_update_time=1758878627627, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS.mlflow')\n",
    "dagshub.init(repo_owner='P-Saroha', repo_name='Sentiment-Analysis-EndToEnd-MLOPS', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 14:53:46,501 - INFO - Starting MLflow run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 14:53:49,028 - INFO - Logging preprocessing parameters...\n",
      "2025-09-26 14:53:50,234 - INFO - Initializing Logistic Regression model...\n",
      "2025-09-26 14:53:50,235 - INFO - Fitting the model...\n",
      "2025-09-26 14:53:50,265 - INFO - Model training complete.\n",
      "2025-09-26 14:53:50,266 - INFO - Logging model parameters...\n",
      "2025-09-26 14:53:50,759 - INFO - Making predictions...\n",
      "2025-09-26 14:53:50,762 - INFO - Calculating evaluation metrics...\n",
      "2025-09-26 14:53:50,790 - INFO - Logging evaluation metrics...\n",
      "2025-09-26 14:53:56,186 - INFO - Saving and logging the model...\n",
      "2025/09/26 14:53:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025-09-26 14:53:57,118 - ERROR - An error occurred: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saroh\\AppData\\Local\\Temp\\ipykernel_16220\\2979654972.py\", line 48, in <module>\n",
      "    mlflow.sklearn.log_model(model, \"model\")\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 426, in log_model\n",
      "    return Model.log(\n",
      "           ^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\models\\model.py\", line 1170, in log\n",
      "    model = _create_logged_model(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py\", line 2307, in _create_logged_model\n",
      "    return MlflowClient()._create_logged_model(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\tracking\\client.py\", line 5446, in _create_logged_model\n",
      "    return self._tracking_client.create_logged_model(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\telemetry\\track.py\", line 30, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py\", line 869, in create_logged_model\n",
      "    return self.store.create_logged_model(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py\", line 922, in create_logged_model\n",
      "    response_proto = self._call_endpoint(CreateLoggedModel, req_body)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py\", line 200, in _call_endpoint\n",
      "    return call_endpoint(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py\", line 554, in call_endpoint\n",
      "    response = verify_rest_response(response, endpoint)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Sentiment-Analysis-EndToEnd-MLOPS\\myenv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py\", line 308, in verify_rest_response\n",
      "    raise RestException(json.loads(response.text))\n",
      "mlflow.exceptions.RestException: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run caring-mouse-109 at: https://dagshub.com/P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS.mlflow/#/experiments/0/runs/16ac4a5bd6b5485c914d5b12ec0df93a\n",
      "üß™ View experiment at: https://dagshub.com/P-Saroha/Sentiment-Analysis-EndToEnd-MLOPS.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 100)\n",
    "        mlflow.log_param(\"test_size\", 0.25)\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        # mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # Print the results for verification\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
